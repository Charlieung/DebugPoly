{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "1    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "2    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "3    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "Name: text, dtype: object 0    DOW JONES, A NEWS CORP COMPANY \\nDJIA\\n?\\n1988...\n",
      "1    \\n \\n       \\nDailyCaller\\n\\n \\n\\nHOME\\nPOLITI...\n",
      "2    \\n \\n       \\nDailyCaller\\n\\n \\n\\nHOME\\nPOLITI...\n",
      "3    \\nPowered by Tynt\\nshare on Facebooktweet this...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Read in Liberal data from txt files\n",
    "data = []\n",
    "\n",
    "for f in os.listdir('./libdata'):\n",
    "    with open('./libdata/' + f, 'r') as myfile:\n",
    "        data.append(myfile.read())\n",
    "        \n",
    "srsLib = pd.Series(data, name = 'text')\n",
    "\n",
    "#Read in Conservative data from txt files\n",
    "data = []\n",
    "\n",
    "for f in os.listdir('./condata'):\n",
    "    with open('./condata/' + f, 'r') as myfile:\n",
    "        data.append(myfile.read())\n",
    "\n",
    "srsCon = pd.Series(data, name = 'text')\n",
    "\n",
    "#len('Message-ID: <2262872.1075863600393.JavaMail.evans@thyme>')\n",
    "#dfSpam = pd.concat([enron, pd.Series([0]*len(enron), name = 'isFood')], axis = 1)\n",
    "#dfSpam.to_csv('enron.csv')\n",
    "#dfSpam.head()\n",
    "\n",
    "print (srsLib, srsCon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "articles = pd.read_csv('../scrape/articles_bias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(articles['bias_score'] == .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles.head(5)\n",
    "[articles['bias_score'] > .5]\n",
    "articles = articles.loc[articles['bias_score'] != .5]\n",
    "articles.loc[articles['bias_score'] > .5, 'bias_score'] = 1\n",
    "articles.loc[articles['bias_score'] < .5 , 'bias_score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    29\n",
       "0.0    29\n",
       "Name: bias_score, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['bias_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>bias_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Running for president, Donald Trump promised a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADVERTISEMENT\\n\\nThe media is sinking to Donal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bill Clark/CQ Roll Call via Getty Images Forme...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Download Topic Description For the Day of Conv...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talking about . . . power and gender equity\\n\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  bias_score\n",
       "0  Running for president, Donald Trump promised a...         0.0\n",
       "1  ADVERTISEMENT\\n\\nThe media is sinking to Donal...         0.0\n",
       "2  Bill Clark/CQ Roll Call via Getty Images Forme...         0.0\n",
       "3  Download Topic Description For the Day of Conv...         0.0\n",
       "4  Talking about . . . power and gender equity\\n\\...         0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[['text', 'bias_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def clean_text(text):\n",
    "    return ' '.join(\n",
    "        RegexpTokenizer(r'\\w+').tokenize(\n",
    "        str.lower(\n",
    "            text\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles['text'] = articles['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35        0.35        0.38888889]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "print(cross_val_score(text_clf, articles['text'], articles['bias_score']))\n",
    "\n",
    "text_clf.fit(articles['text'], articles['bias_score'])\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(text_clf, 'text_clf.pkl')\n",
    "\n",
    "# predicted = text_clf.predict(X_test)\n",
    "# np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    83\n",
       "1.0    29\n",
       "Name: bias_score, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['bias_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.89402133e-01,   1.05978667e-02],\n",
       "       [  9.80344969e-01,   1.96550309e-02],\n",
       "       [  9.59576342e-01,   4.04236581e-02],\n",
       "       [  9.99461730e-01,   5.38269706e-04],\n",
       "       [  9.99822075e-01,   1.77925493e-04],\n",
       "       [  9.99797443e-01,   2.02557057e-04],\n",
       "       [  9.99749850e-01,   2.50150104e-04],\n",
       "       [  9.99734161e-01,   2.65838988e-04],\n",
       "       [  9.84628932e-01,   1.53710680e-02],\n",
       "       [  9.76317000e-01,   2.36830000e-02],\n",
       "       [  9.37416922e-01,   6.25830781e-02],\n",
       "       [  9.99781049e-01,   2.18950517e-04],\n",
       "       [  9.60346329e-01,   3.96536712e-02],\n",
       "       [  9.99861523e-01,   1.38476757e-04],\n",
       "       [  9.87805238e-01,   1.21947621e-02],\n",
       "       [  9.85844221e-01,   1.41557792e-02],\n",
       "       [  9.77875190e-01,   2.21248096e-02],\n",
       "       [  9.99708438e-01,   2.91562047e-04],\n",
       "       [  9.85301222e-01,   1.46987778e-02],\n",
       "       [  9.77896248e-01,   2.21037523e-02],\n",
       "       [  9.99877453e-01,   1.22546905e-04],\n",
       "       [  9.79267299e-01,   2.07327011e-02],\n",
       "       [  9.99821467e-01,   1.78532918e-04],\n",
       "       [  9.75471417e-01,   2.45285834e-02],\n",
       "       [  9.80032769e-01,   1.99672310e-02],\n",
       "       [  8.17452536e-01,   1.82547464e-01],\n",
       "       [  9.99044795e-01,   9.55204904e-04],\n",
       "       [  9.43399733e-01,   5.66002668e-02],\n",
       "       [  9.99813641e-01,   1.86359229e-04],\n",
       "       [  9.99566986e-01,   4.33013763e-04],\n",
       "       [  9.65702452e-01,   3.42975480e-02],\n",
       "       [  9.58301307e-01,   4.16986925e-02],\n",
       "       [  9.79187369e-01,   2.08126313e-02],\n",
       "       [  9.19238309e-01,   8.07616913e-02],\n",
       "       [  9.75832902e-01,   2.41670980e-02],\n",
       "       [  9.91729625e-01,   8.27037484e-03],\n",
       "       [  9.99835444e-01,   1.64555889e-04],\n",
       "       [  9.99469748e-01,   5.30251834e-04],\n",
       "       [  9.99686401e-01,   3.13598767e-04],\n",
       "       [  9.85539794e-01,   1.44602056e-02],\n",
       "       [  9.34095404e-01,   6.59045964e-02],\n",
       "       [  9.78578237e-01,   2.14217629e-02],\n",
       "       [  9.99792043e-01,   2.07957078e-04],\n",
       "       [  9.76497816e-01,   2.35021842e-02],\n",
       "       [  9.99118501e-01,   8.81499356e-04],\n",
       "       [  5.73540034e-01,   4.26459966e-01],\n",
       "       [  9.99785498e-01,   2.14502106e-04],\n",
       "       [  9.35881134e-01,   6.41188661e-02],\n",
       "       [  9.99669363e-01,   3.30636778e-04],\n",
       "       [  9.75289870e-01,   2.47101300e-02],\n",
       "       [  9.83338548e-01,   1.66614519e-02],\n",
       "       [  9.99230756e-01,   7.69244146e-04],\n",
       "       [  9.60136331e-01,   3.98636695e-02],\n",
       "       [  9.62942466e-01,   3.70575337e-02],\n",
       "       [  9.87798575e-01,   1.22014248e-02],\n",
       "       [  9.37393363e-01,   6.26066372e-02],\n",
       "       [  9.06341371e-01,   9.36586290e-02],\n",
       "       [  9.90074294e-01,   9.92570571e-03],\n",
       "       [  9.84836692e-01,   1.51633081e-02],\n",
       "       [  9.84188022e-01,   1.58119782e-02],\n",
       "       [  9.90530499e-01,   9.46950127e-03],\n",
       "       [  9.99800888e-01,   1.99111870e-04],\n",
       "       [  9.74678235e-01,   2.53217646e-02],\n",
       "       [  9.99297565e-01,   7.02434786e-04],\n",
       "       [  9.38236596e-01,   6.17634037e-02],\n",
       "       [  9.88744425e-01,   1.12555749e-02],\n",
       "       [  9.53750808e-01,   4.62491925e-02],\n",
       "       [  9.69591682e-01,   3.04083177e-02],\n",
       "       [  9.86383802e-01,   1.36161979e-02],\n",
       "       [  9.44792068e-01,   5.52079318e-02],\n",
       "       [  9.84791289e-01,   1.52087107e-02],\n",
       "       [  9.99764766e-01,   2.35233799e-04],\n",
       "       [  9.30580149e-01,   6.94198510e-02],\n",
       "       [  9.70863419e-01,   2.91365808e-02],\n",
       "       [  9.90228947e-01,   9.77105325e-03],\n",
       "       [  9.28196068e-01,   7.18039317e-02],\n",
       "       [  8.34061032e-01,   1.65938968e-01],\n",
       "       [  9.84774460e-01,   1.52255396e-02],\n",
       "       [  9.83734160e-01,   1.62658403e-02],\n",
       "       [  9.83202899e-01,   1.67971006e-02],\n",
       "       [  9.83897020e-01,   1.61029799e-02],\n",
       "       [  9.99840197e-01,   1.59803087e-04],\n",
       "       [  9.77039572e-01,   2.29604282e-02],\n",
       "       [  9.99704642e-01,   2.95357778e-04],\n",
       "       [  9.99737137e-01,   2.62863198e-04],\n",
       "       [  9.99753437e-01,   2.46563382e-04],\n",
       "       [  9.60987736e-01,   3.90122643e-02],\n",
       "       [  9.80286872e-01,   1.97131276e-02],\n",
       "       [  9.48903132e-01,   5.10968685e-02],\n",
       "       [  9.78216954e-01,   2.17830465e-02],\n",
       "       [  9.78278317e-01,   2.17216826e-02],\n",
       "       [  9.84169088e-01,   1.58309123e-02],\n",
       "       [  9.62554508e-01,   3.74454921e-02],\n",
       "       [  9.90045631e-01,   9.95436856e-03],\n",
       "       [  9.36014408e-01,   6.39855924e-02],\n",
       "       [  9.89663304e-01,   1.03366965e-02],\n",
       "       [  8.59970460e-01,   1.40029540e-01],\n",
       "       [  9.83606556e-01,   1.63934437e-02],\n",
       "       [  9.99705873e-01,   2.94127424e-04],\n",
       "       [  9.89633755e-01,   1.03662453e-02],\n",
       "       [  9.78111346e-01,   2.18886539e-02],\n",
       "       [  9.99172146e-01,   8.27854230e-04],\n",
       "       [  9.82823200e-01,   1.71768005e-02],\n",
       "       [  9.13164499e-01,   8.68355008e-02],\n",
       "       [  9.36884328e-01,   6.31156722e-02],\n",
       "       [  9.76077574e-01,   2.39224256e-02],\n",
       "       [  9.84288397e-01,   1.57116028e-02],\n",
       "       [  9.99832776e-01,   1.67223540e-04],\n",
       "       [  8.82086022e-01,   1.17913978e-01],\n",
       "       [  9.50421326e-01,   4.95786738e-02],\n",
       "       [  9.44104086e-01,   5.58959142e-02],\n",
       "       [  9.24234025e-01,   7.57659750e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict_proba(articles[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_clf.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(text_clf, 'text_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_estimator_type',\n",
       " '_final_estimator',\n",
       " '_fit',\n",
       " '_get_param_names',\n",
       " '_get_params',\n",
       " '_inverse_transform',\n",
       " '_pairwise',\n",
       " '_replace_step',\n",
       " '_set_params',\n",
       " '_transform',\n",
       " '_validate_names',\n",
       " '_validate_steps',\n",
       " 'classes_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'fit_predict',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'named_steps',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'steps',\n",
       " 'transform']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(text_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__',\n",
       " '__add__',\n",
       " '__array_priority__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__idiv__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__numpy_ufunc__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmatmul__',\n",
       " '__rmul__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '_binopt',\n",
       " '_boolean_index_to_array',\n",
       " '_check_boolean',\n",
       " '_check_ellipsis',\n",
       " '_cs_matrix__get_has_canonical_format',\n",
       " '_cs_matrix__get_sorted',\n",
       " '_cs_matrix__set_has_canonical_format',\n",
       " '_cs_matrix__set_sorted',\n",
       " '_deduped_data',\n",
       " '_divide',\n",
       " '_divide_sparse',\n",
       " '_get_dtype',\n",
       " '_get_row_slice',\n",
       " '_get_single_element',\n",
       " '_get_submatrix',\n",
       " '_imag',\n",
       " '_index_to_arrays',\n",
       " '_inequality',\n",
       " '_insert_many',\n",
       " '_maximum_minimum',\n",
       " '_min_or_max',\n",
       " '_min_or_max_axis',\n",
       " '_minor_reduce',\n",
       " '_mul_multivector',\n",
       " '_mul_scalar',\n",
       " '_mul_sparse_matrix',\n",
       " '_mul_vector',\n",
       " '_prepare_indices',\n",
       " '_process_toarray_args',\n",
       " '_real',\n",
       " '_scalar_binopt',\n",
       " '_set_dtype',\n",
       " '_set_many',\n",
       " '_set_self',\n",
       " '_setdiag',\n",
       " '_shape',\n",
       " '_slicetoarange',\n",
       " '_swap',\n",
       " '_unpack_index',\n",
       " '_with_data',\n",
       " '_zero_many',\n",
       " 'arcsin',\n",
       " 'arcsinh',\n",
       " 'arctan',\n",
       " 'arctanh',\n",
       " 'asformat',\n",
       " 'asfptype',\n",
       " 'astype',\n",
       " 'ceil',\n",
       " 'check_format',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'count_nonzero',\n",
       " 'data',\n",
       " 'deg2rad',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'eliminate_zeros',\n",
       " 'expm1',\n",
       " 'floor',\n",
       " 'format',\n",
       " 'getH',\n",
       " 'get_shape',\n",
       " 'getcol',\n",
       " 'getformat',\n",
       " 'getmaxprint',\n",
       " 'getnnz',\n",
       " 'getrow',\n",
       " 'has_canonical_format',\n",
       " 'has_sorted_indices',\n",
       " 'indices',\n",
       " 'indptr',\n",
       " 'log1p',\n",
       " 'max',\n",
       " 'maximum',\n",
       " 'maxprint',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'nnz',\n",
       " 'nonzero',\n",
       " 'power',\n",
       " 'prune',\n",
       " 'rad2deg',\n",
       " 'reshape',\n",
       " 'rint',\n",
       " 'set_shape',\n",
       " 'setdiag',\n",
       " 'shape',\n",
       " 'sign',\n",
       " 'sin',\n",
       " 'sinh',\n",
       " 'sort_indices',\n",
       " 'sorted_indices',\n",
       " 'sqrt',\n",
       " 'sum',\n",
       " 'sum_duplicates',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'toarray',\n",
       " 'tobsr',\n",
       " 'tocoo',\n",
       " 'tocsc',\n",
       " 'tocsr',\n",
       " 'todense',\n",
       " 'todia',\n",
       " 'todok',\n",
       " 'tolil',\n",
       " 'transpose',\n",
       " 'trunc']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cv_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isLib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dow jones a news corp company djia 19885 73 0 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  isLib\n",
       "0  sections home searchskip to contentskip to nav...      1\n",
       "1  sections home searchskip to contentskip to nav...      1\n",
       "2  sections home searchskip to contentskip to nav...      1\n",
       "3  sections home searchskip to contentskip to nav...      1\n",
       "0  dow jones a news corp company djia 19885 73 0 ...      0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def preProc(text):\n",
    "    return ' '.join(\n",
    "        RegexpTokenizer(r'\\w+').tokenize(\n",
    "        str.lower(\n",
    "            text\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "#    Stem the tokens\n",
    "\n",
    "#Join and classify as lib or not lib\n",
    "dfLib = pd.concat([srsLib.apply(preProc), pd.Series([1]*len(srsLib), name = 'isLib')], axis = 1)\n",
    "dfCon = pd.concat([srsCon.apply(preProc), pd.Series([0]*len(srsCon), name = 'isLib')], axis = 1)\n",
    "dfData = dfLib.append(dfCon)\n",
    "dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split into train and test set\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = dfData['text']\n",
    "y = dfData['isLib']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create vector of word counts SKIP\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#count_vect = CountVectorizer()\n",
    "\n",
    "#X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create tfidf sprase matrix SKIP\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fit model SKIP\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#clf = MultinomialNB().fit(X_train_tfidf, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(text_clf, 'text_clf.pkl')\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
