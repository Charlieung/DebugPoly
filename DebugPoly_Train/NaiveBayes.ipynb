{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "articles = pd.DataFrame()\n",
    "\n",
    "for f in os.listdir('../scrape/data/'):\n",
    "    articles = articles.append(pd.read_csv('../scrape/data/' + f))\n",
    "    \n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BIAS_NAME_TO_SCORE = {\n",
    "    'Bias: Left': 0,\n",
    "    'Bias: Lean Left': .25,\n",
    "    'Bias: Center': .5,\n",
    "    'Bias: Mixed': .5,\n",
    "    'Bias: Lean Right': .75,\n",
    "    'Bias: Right': 1\n",
    "}\n",
    "\n",
    "articles = articles[articles['bias'] != 'Bias: Not rated']\n",
    "articles['bias_score'] = articles[\"bias\"].map(BIAS_NAME_TO_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles = articles.loc[articles['bias_score'] != .5]\n",
    "articles.loc[articles['bias_score'] > .5, 'bias_score'] = 1\n",
    "articles.loc[articles['bias_score'] < .5 , 'bias_score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    338\n",
       "1.0    320\n",
       "Name: bias_score, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['bias_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>bias</th>\n",
       "      <th>keywords</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>bias_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Lauren Gambino']</td>\n",
       "      <td>Bias: Lean Left</td>\n",
       "      <td>['healthcare', 'replacement', 'congress', 'mea...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Republicans ready to dismantle Obamacare amid ...</td>\n",
       "      <td>Congress approves initial measures to repeal A...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Washington Times Http', 'Tom Howell Jr.']</td>\n",
       "      <td>Bias: Lean Right</td>\n",
       "      <td>['way', 'house', 'health', 'care', 'budget', '...</td>\n",
       "      <td>Washington Times</td>\n",
       "      <td>The House passed a 2017 budget Friday that lay...</td>\n",
       "      <td>House passes budget to begin Obamacare repeal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[\"Cortney O'Brien\", 'Christine Rousselle', 'Ju...</td>\n",
       "      <td>Bias: Right</td>\n",
       "      <td>['agency', 'department', 'doj', 'chicago', 'pr...</td>\n",
       "      <td>Townhall</td>\n",
       "      <td>Garry McCarthy was the superintendent of the C...</td>\n",
       "      <td>Former Chicago Police Superintendent: The DOJ ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Mark Berman Covers National News For The Was...</td>\n",
       "      <td>Bias: Lean Left</td>\n",
       "      <td>['city', 'scathing', 'force', 'pattern', 'just...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>During a press conference on Jan. 13, Attorney...</td>\n",
       "      <td>Chicago police officers have pattern of using ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>Bias: Right</td>\n",
       "      <td>['relationship', 'think', 'ill', 'relations', ...</td>\n",
       "      <td>CBN</td>\n",
       "      <td>President-elect Donald Trump has responded to ...</td>\n",
       "      <td>Tough Times ahead for White House-Media Relati...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            authors  \\\n",
       "0           0                                 ['Lauren Gambino']   \n",
       "2           2    ['The Washington Times Http', 'Tom Howell Jr.']   \n",
       "3           3  [\"Cortney O'Brien\", 'Christine Rousselle', 'Ju...   \n",
       "4           4  ['Mark Berman Covers National News For The Was...   \n",
       "6           6                                                 []   \n",
       "\n",
       "               bias                                           keywords  \\\n",
       "0   Bias: Lean Left  ['healthcare', 'replacement', 'congress', 'mea...   \n",
       "2  Bias: Lean Right  ['way', 'house', 'health', 'care', 'budget', '...   \n",
       "3       Bias: Right  ['agency', 'department', 'doj', 'chicago', 'pr...   \n",
       "4   Bias: Lean Left  ['city', 'scathing', 'force', 'pattern', 'just...   \n",
       "6       Bias: Right  ['relationship', 'think', 'ill', 'relations', ...   \n",
       "\n",
       "             source                                               text  \\\n",
       "0      The Guardian  Republicans ready to dismantle Obamacare amid ...   \n",
       "2  Washington Times  The House passed a 2017 budget Friday that lay...   \n",
       "3          Townhall  Garry McCarthy was the superintendent of the C...   \n",
       "4   Washington Post  During a press conference on Jan. 13, Attorney...   \n",
       "6               CBN  President-elect Donald Trump has responded to ...   \n",
       "\n",
       "                                               title  bias_score  \n",
       "0  Congress approves initial measures to repeal A...         0.0  \n",
       "2      House passes budget to begin Obamacare repeal         1.0  \n",
       "3  Former Chicago Police Superintendent: The DOJ ...         1.0  \n",
       "4  Chicago police officers have pattern of using ...         0.0  \n",
       "6  Tough Times ahead for White House-Media Relati...         1.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles = articles.loc[articles['text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def clean_text(text):\n",
    "    return ' '.join(\n",
    "        RegexpTokenizer(r'\\w+').tokenize(\n",
    "        str.lower(\n",
    "            text\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "articles['text'] = articles['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'vect__ngram_range': [(1, 1), (1, 2)]}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:    7.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:    9.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:   15.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   6 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 16.594s\n",
      "\n",
      "Best score: 0.534\n",
      "Best parameters set:\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               #'tfidf__use_idf': (True, False),\n",
    "               #'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in text_clf.steps])\n",
    "print(\"parameters:\")\n",
    "\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "\n",
    "grid_search.fit(articles['text'], articles['bias_score'])\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_clf.pkl',\n",
       " 'text_clf.pkl_01.npy',\n",
       " 'text_clf.pkl_02.npy',\n",
       " 'text_clf.pkl_03.npy',\n",
       " 'text_clf.pkl_04.npy',\n",
       " 'text_clf.pkl_05.npy',\n",
       " 'text_clf.pkl_06.npy',\n",
       " 'text_clf.pkl_07.npy',\n",
       " 'text_clf.pkl_08.npy',\n",
       " 'text_clf.pkl_09.npy']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dump file into pickle object\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid_search, 'text_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16666029420499082,\n",
       " 0.45001012670211382,\n",
       " 0.32954048979897832,\n",
       " 0.26576671160649273,\n",
       " 0.26347487636080386,\n",
       " 0.35289495418404238,\n",
       " 0.52898080544576476,\n",
       " 0.54356627777610544,\n",
       " 0.48478954690145343,\n",
       " 0.30264724331482984,\n",
       " 0.30119403583039195,\n",
       " 0.23645595802604766,\n",
       " 0.16546944976328454,\n",
       " 0.25135593441902054,\n",
       " 0.36785578186346962,\n",
       " 0.50726598483715191,\n",
       " 0.17970131404671297,\n",
       " 0.36949947670914873,\n",
       " 0.50532084741285288,\n",
       " 0.64102825379701112)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*grid_search.predict_proba(y_train)))[1] #These are the predictions in probability."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
