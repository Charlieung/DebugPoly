{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "1    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "2    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "3    SECTIONS HOME SEARCHSKIP TO CONTENTSKIP TO NAV...\n",
      "Name: text, dtype: object 0    DOW JONES, A NEWS CORP COMPANY \\nDJIA\\n?\\n1988...\n",
      "1    \\n \\n       \\nDailyCaller\\n\\n \\n\\nHOME\\nPOLITI...\n",
      "2    \\n \\n       \\nDailyCaller\\n\\n \\n\\nHOME\\nPOLITI...\n",
      "3    \\nPowered by Tynt\\nshare on Facebooktweet this...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Read in Liberal data from txt files\n",
    "data = []\n",
    "\n",
    "for f in os.listdir('./libdata'):\n",
    "    with open('./libdata/' + f, 'r') as myfile:\n",
    "        data.append(myfile.read())\n",
    "        \n",
    "srsLib = pd.Series(data, name = 'text')\n",
    "\n",
    "#Read in Conservative data from txt files\n",
    "data = []\n",
    "\n",
    "for f in os.listdir('./condata'):\n",
    "    with open('./condata/' + f, 'r') as myfile:\n",
    "        data.append(myfile.read())\n",
    "\n",
    "srsCon = pd.Series(data, name = 'text')\n",
    "\n",
    "#len('Message-ID: <2262872.1075863600393.JavaMail.evans@thyme>')\n",
    "#dfSpam = pd.concat([enron, pd.Series([0]*len(enron), name = 'isFood')], axis = 1)\n",
    "#dfSpam.to_csv('enron.csv')\n",
    "#dfSpam.head()\n",
    "\n",
    "print (srsLib, srsCon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isLib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sections home searchskip to contentskip to nav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dow jones a news corp company djia 19885 73 0 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  isLib\n",
       "0  sections home searchskip to contentskip to nav...      1\n",
       "1  sections home searchskip to contentskip to nav...      1\n",
       "2  sections home searchskip to contentskip to nav...      1\n",
       "3  sections home searchskip to contentskip to nav...      1\n",
       "0  dow jones a news corp company djia 19885 73 0 ...      0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing text, split string into list of words\n",
    "escapes = [chr(char) for char in range(1,32)]\n",
    "escapes.append('\\x92')\n",
    "escapes.append('\\x97')\n",
    "\n",
    "#remove escape chars as spaces\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "\n",
    "def preProc(text):\n",
    "    return ' '.join(\n",
    "        RegexpTokenizer(r'\\w+').tokenize(\n",
    "        str.lower(\n",
    "            text\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "#    Stem the tokens\n",
    "\n",
    "#Join and classify as lib or not lib\n",
    "dfLib = pd.concat([srsLib.apply(preProc), pd.Series([1]*len(srsLib), name = 'isLib')], axis = 1)\n",
    "dfCon = pd.concat([srsCon.apply(preProc), pd.Series([0]*len(srsCon), name = 'isLib')], axis = 1)\n",
    "dfData = dfLib.append(dfCon)\n",
    "dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split into train and test set\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = dfData['text']\n",
    "y = dfData['isLib']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create vector of word counts SKIP\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#count_vect = CountVectorizer()\n",
    "\n",
    "#X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create tfidf sprase matrix SKIP\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fit model SKIP\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#clf = MultinomialNB().fit(X_train_tfidf, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(text_clf, 'text_clf.pkl')\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
